{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CF_Social_Autoencoder.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmineSdk/RecommenderSystem/blob/main/Notebook/CF_Social_Autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-text"
      ],
      "metadata": {
        "id": "nFsPPT0-cZms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets download CellPhones -f CellPhonesRating.csv"
      ],
      "metadata": {
        "id": "UM0vifCk9CB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "TcGcg4ZzRQD1"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "from scipy.sparse import csr_matrix\n",
        "import tensorflow as tf \n",
        "import numpy as np\n",
        "import tensorflow_hub as hub\n",
        "import pandas as pd\n",
        "import random\n",
        "from keras import datasets, layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from progressbar import progressbar"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA = ['/content/CellPhonesRating_50K_reviews.csv','yelp_rating_mat','yelp_user_mat']\n",
        "MODEL_PATH = []\n",
        "PATH = ''\n",
        "rmse = tf.keras.metrics.RootMeanSquaredError()\n",
        "precision = tf.keras.metrics.Precision()\n",
        "METRICS = ['accuracy','mae',rmse,precision]"
      ],
      "metadata": {
        "id": "MbQZ8yLYOnWI"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/CellPhonesRating.csv.zip')"
      ],
      "metadata": {
        "id": "K_fZblYVAeGg"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sample = df[:50000]\n",
        "df_sample.to_csv('/content/CellPhonesRating_50K_reviews.csv')"
      ],
      "metadata": {
        "id": "xw_P6DJzAa7n"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sample['productID'].nunique()"
      ],
      "metadata": {
        "id": "2YFUZLlNESK1",
        "outputId": "01c93ed1-cd7f-4963-bfdd-fbda8db0d748",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3138"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_sample['reviewerID'].nunique()"
      ],
      "metadata": {
        "id": "i6pbXRh-EHDC",
        "outputId": "5dacad3a-5894-4a86-d933-4b3d95dd586b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34064"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/yelp-user-user-trust.zip\" -d \"/content/\"\n",
        "!unzip \"/content/yelp-review-ratings.zip\" -d \"/content/\""
      ],
      "metadata": {
        "id": "ppVGlIh8Ce8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def DatasetToUserItemDataFrame(dataframe,userID,itemID,rating):\n",
        "  #Setting new item IDs from string to int \n",
        "  itemKeys = [] \n",
        "  i = 0\n",
        "  for item in dataframe[itemID].value_counts(sort=False):\n",
        "    temp = np.full((item),i)\n",
        "    itemKeys = np.append(itemKeys,temp)\n",
        "    i += 1\n",
        "\n",
        "  #Setting new user IDs from string to int\n",
        "  userKeysDic = {}\n",
        "  userKeys = np.zeros((dataframe[userID].size))\n",
        "  i = 0\n",
        "  for user in dataframe[userID].unique():\n",
        "    userKeysDic[user] = i\n",
        "    i += 1\n",
        "  i = 0\n",
        "  for user in dataframe[userID]:\n",
        "    userKeys[i] = userKeysDic[user]\n",
        "    i += 1\n",
        "\n",
        "  #Converting arrays from float to int \n",
        "  userKeys = userKeys.astype(int)\n",
        "  itemKeys = itemKeys.astype(int)\n",
        "\n",
        "  \n",
        "  user_item = csr_matrix((dataframe[rating].values.astype(int),(userKeys,itemKeys))) #Creating sparse matrix\n",
        "  user_item_matrix = user_item.toarray() #Converting sparse matrix into array\n",
        "  df_user_item = pd.DataFrame(user_item_matrix,index = dataframe[userID].unique()  ,columns = dataframe[itemID].unique() ) \n",
        "\n",
        "  return df_user_item"
      ],
      "metadata": {
        "id": "HHmzbMvDVB0b"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getUsersRatings(df,usersList): #returns df_rating containing only users that have friends \n",
        "  temp = df.copy()\n",
        "  for user in list(df['userID']):\n",
        "    if user not in usersList:\n",
        "      temp = temp.drop(temp.loc[temp['userID'] == user].index)\n",
        "  return temp"
      ],
      "metadata": {
        "id": "fbVQ62DroVDu"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def genIndexColumn(df,min_index,max_index,min_column,max_column): #generates random int index and columns for a given df\n",
        "  New_User_IDs = random.sample(range(min_index,max_index),df.index.size)\n",
        "  New_Item_IDs = random.sample(range(min_column,max_column),df.columns.size)\n",
        "\n",
        "  df_new = pd.DataFrame(df.to_numpy(),index = New_User_IDs,columns = New_Item_IDs)\n",
        "  return df_new"
      ],
      "metadata": {
        "id": "5a5J7Mkt5yzm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generateIDs(df,index,columns,min_index,max_index,min_column,max_column):\n",
        "  users = df[index].unique()\n",
        "  items = df[columns].unique()\n",
        "  df_train = df.copy()\n",
        "\n",
        "  New_User_IDs = random.sample(range(min_index,max_index),df[index].nunique())\n",
        "  New_Item_IDs = random.sample(range(min_column,max_column),df[columns].nunique())\n",
        "  i = 0\n",
        "  for d in progressbar(users) :\n",
        "    df_train[index].replace({d : New_User_IDs[i]}, inplace=True)\n",
        "    i+=1\n",
        "\n",
        "  i = 0\n",
        "  for d in progressbar(items) :\n",
        "    df_train[columns].replace({d : New_Item_IDs[i]}, inplace=True)\n",
        "    i+=1\n",
        "  return df_train"
      ],
      "metadata": {
        "id": "mmzsdMDPmC8I"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def processGmfData(df,index,column,min_user_id,max_user_id,min_item_id,max_item_id):\n",
        "  \n",
        "  \n",
        "  #df.rename(columns = {'text': 'reviewText', 'stars': 'rating', 'business_id': 'itemID', 'user_id': 'userID'}, inplace = True)\n",
        "  df.rename(columns = {'reviewerID':'userID', 'productID' : 'itemID'},inplace = True)\n",
        "  df = generateIDs(df,index,column,min_user_id,max_user_id,min_item_id,max_item_id)\n",
        "  print(\"== PREPROCESSING DATA ...\")\n",
        "  df = df.dropna(how='any',axis=0)\n",
        "  df.drop_duplicates(subset =['itemID', 'userID'] , keep = 'first' , inplace = True)\n",
        "\n",
        "  df['one'] = df['rating'].apply(lambda x: 1 if x==1 else 0)\n",
        "  df['two'] = df['rating'].apply(lambda x: 1 if x==2 else 0)\n",
        "  df['three'] = df['rating'].apply(lambda x: 1 if x==3 else 0)\n",
        "  df['four'] = df['rating'].apply(lambda x: 1 if x==4 else 0)\n",
        "  df['five'] = df['rating'].apply(lambda x: 1 if x==5 else 0)\n",
        "  #df['six'] = df['rating'].apply(lambda x: 1 if x==6 else 0)\n",
        "  print(\"== DATA PREPROCESSED ==\")\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "08ifZdzgO2u9"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GMF\n",
        "def getGMFmodel(num_users,num_items,SIZE_):\n",
        "\n",
        "  input_userID = layers.Input(shape=[1], name='user_ID')\n",
        "  input_itemID = layers.Input(shape=[1], name='item_ID')\n",
        "\n",
        "  user_emb_GMF = layers.Embedding(num_users, SIZE_, name='user_emb_GMF')(input_userID)\n",
        "  item_emb_GMF = layers.Embedding(num_items, SIZE_, name='item_emb_GMF')(input_itemID)\n",
        "\n",
        "  u_GMF = layers.Flatten()(user_emb_GMF)\n",
        "  i_GMF = layers.Flatten()(item_emb_GMF)\n",
        "\n",
        "  dot_layer = layers.Multiply()([u_GMF, i_GMF])\n",
        "\n",
        "  out_layer = layers.Dense(5, activation='softmax', name='output')(dot_layer)\n",
        "\n",
        "  GMF = tf.keras.Model([input_userID, input_itemID], out_layer)\n",
        "  \n",
        "  return GMF\n",
        "\n",
        "\n",
        "def user_item_ID_lists(userIDs,itemIDs):\n",
        "  i = 0\n",
        "  item_s = pd.Series()\n",
        "  user_s = pd.Series()\n",
        "  for user in progressbar(userIDs):\n",
        "    temp = pd.Series(itemIDs)\n",
        "    item_s = item_s.append(temp)\n",
        "    temp = []\n",
        "    temp = [user for item in itemIDs]\n",
        "    temp = pd.Series(temp)\n",
        "    user_s = user_s.append(temp)\n",
        "\n",
        "  return user_s,item_s\n",
        "\n",
        "def Fill_Cf_Matrix(model,userList,itemList,userIDs,itemIDs):\n",
        "\n",
        "  prediction = model.predict([userList,itemList],verbose = 1)\n",
        "  i = 0\n",
        "  row = []\n",
        "  matrix = []\n",
        "  print(\"pred done\")\n",
        "\n",
        "  while i < userList.shape[0]:\n",
        "    result = np.where(prediction[i] == np.amax(prediction[i]))[0][0] + 1\n",
        "    row.append(result)\n",
        "    if len(row) == itemIDs.size:\n",
        "      matrix.append(row)\n",
        "      row = []\n",
        "       \n",
        "    i += 1\n",
        "\n",
        "  matrix_arr = np.array(matrix)\n",
        "  dataframe = pd.DataFrame(matrix_arr, index = userIDs, columns = itemIDs)\n",
        "  \n",
        "  return dataframe\n",
        "\n",
        "def loadDataset(fileID):\n",
        "  dataset = pd.read_csv(DATA[fileID])\n",
        "  print(\"== FILE LOADED ==\")\n",
        "  return dataset\n",
        "\n",
        "def saveDataframe(df,fileID):\n",
        "  file_path = PATH+'GMF_filled_'+DATA[fileID]\n",
        "  df.to_csv(file_path)\n",
        "\n",
        "def genGMFmat(df,df_test,modelID,fileID,nbrE,lossF,OF,emb,filter=None,cb=None):\n",
        "\n",
        "  # df_og = loadDataset(fileID)\n",
        "  # df = processGmfData(df_og,'userID','itemID',1000,2000+df_og['reviewerID'].nunique(),60000,61000+df_og['productID'].nunique())\n",
        "  \n",
        "  x_train ,x_test,y_train,y_test = train_test_split(df_test[['userID','itemID']],df_test[['one','two','three','four','five']],test_size=0.2,stratify=df_test[['one','two','three','four','five']])\n",
        "  model_trained = trainModel(modelID,nbrE,lossF,OF,[x_train['userID'],x_train['itemID']],y_train,maxUserID=df_test['userID'].max() + 1,maxItemID =df_test['itemID'].max() + 1,embed_size=emb)\n",
        "  model_trained.evaluate([x_test['userID'],x_test['itemID']],y_test)\n",
        "\n",
        "  df_mat_filled = FillSparseMat(model_trained,df_test,df)\n",
        "  \n",
        "  return df_mat_filled\n",
        "\n",
        "def FillSparseMat(model,df_prepro,df_og):\n",
        "\n",
        "  user_s,item_s = user_item_ID_lists(df_prepro['userID'].unique(),df_prepro['itemID'].unique())\n",
        "  df_mat_filled = Fill_Cf_Matrix(model,user_s,item_s,df_og['userID'].unique(),df_og['itemID'].unique())\n",
        "\n",
        "  return df_mat_filled\n",
        "\n",
        "\n",
        "def trainModel(modelID,nbrEpochs,lossF,OF,x_train ,y_train ,mid_layer_ratio=None,nb_layers=None,maxUserID = None,maxItemID = None,embed_size = None,filter_size = None):\n",
        "  \n",
        "  if modelID =='BLCNN':\n",
        "    model = getBLCNNmodel(embed_size,filter_size)\n",
        "  if modelID == 'GMF':\n",
        "    model = getGMFmodel(maxUserID,maxItemID,embed_size)\n",
        "  elif modelID == 'S-AutoCF':\n",
        "    model = getAutoCFmodel(x_train,mid_layer_ratio,nb_layers)\n",
        "  elif modelID == 'SS-AutoCF':\n",
        "    model = getSS_HAEmodel(x_train,mid_layer_ratio,nb_layers)\n",
        "\n",
        "  model.compile(optimizer = OF,\n",
        "                    loss = lossF,\n",
        "                    metrics= METRICS)\n",
        "  model.fit(x_train,y_train,epochs = nbrEpochs,validation_split=0.14)\n",
        "  \n",
        "  return model\n",
        "\n",
        "def getAutoCFmodel(x_train,mid_layer_ratio,nb_layers):\n",
        "  #mid_layer_ratio [0 - 1]\n",
        "  layer_ratio =  mid_layer_ratio + nb_layers*0.1\n",
        "\n",
        "  encoder_input = layers.Input(shape=(x_train.shape[1]),name='user_item')\n",
        "  flat = layers.Flatten()(encoder_input)\n",
        "  for i in range(nb_layers):\n",
        "    hid_encoder = layers.Dense(layer_ratio*x_train.shape[1],activation=\"relu\")(hid_encoder)\n",
        "    layer_ratio -= 0.1\n",
        "  hid_encoder(flat)\n",
        "  encoder_output = layers.Dense(mid_layer_ratio*x_train.shape[1],activation=\"relu\")(hid_encoder)\n",
        "  for i in range(nb_layers):\n",
        "    decoder_input = layers.Dense(layer_ratio*x_train.shape[1],activation=\"relu\")(decoder_input)\n",
        "    layer_ratio += 0.1\n",
        "  decoder_input(encoder_output)\n",
        "  decoder_output = layers.Dense(x_train.shape[1],activation=\"relu\")(decoder_input)\n",
        "\n",
        "  autoencoder = tf.keras.Model(inputs = encoder_input, outputs = decoder_output)\n",
        "\n",
        "  return autoencoder\n",
        "\n",
        "def getSS_HAEmodel(x_train,mid_layer_ratio,nb_layers):\n",
        "  \n",
        "  #mid_layer_ratio [0 - 1]\n",
        "  layer_ratio =  mid_layer_ratio + nb_layers*0.1\n",
        "\n",
        "  #Social_Autoencoder\n",
        "\n",
        "  rating_input = layers.Input(shape=(x_train.shape[1]),name='user_item')\n",
        "  social_input = layers.Input(shape=(x_train.shape[1]),name='user_user')\n",
        "\n",
        "  flat_rating = layers.Flatten()(rating_input)\n",
        "  flat_social = layers.Flatten()(social_input)\n",
        "\n",
        "  #dropout = layers.Dropout(.2)(flat)\n",
        "  SharedLayer_encoder = layers.Concatenate()([flat_rating,flat_social])\n",
        "  for i in range(nb_layers):\n",
        "    hid_encoder = layers.Dense(layer_ratio*x_train.shape[1],activation=\"relu\")(hid_encoder)\n",
        "    layer_ratio -= 0.1\n",
        "  hid_encoder(SharedLayer_encoder)\n",
        "  encoder_output = layers.Dense(mid_layer_ratio,activation=\"relu\")(hid_encoder)\n",
        "  for i in range(nb_layers):\n",
        "    hid_decoder = layers.Dense(layer_ratio*x_train.shape[1],activation=\"relu\")(hid_decoder)\n",
        "    layer_ratio += 0.1\n",
        "  hid_decoder(encoder_output)\n",
        "  SharedLayer_decoder =  layers.Dense(df_mat_rating.shape[1]+df_mat_trust.shape[1],activation=\"relu\")(hid_decoder)\n",
        "  rating_decoded , social_decoded = tf.split(SharedLayer_decoder,[df_mat_rating.shape[1],df_mat_trust.shape[1]],1)\n",
        "\n",
        "  rating_output = layers.Dense(df_mat_rating.shape[1],activation=\"relu\",name='rating_output')(rating_decoded)\n",
        "  social_output = layers.Dense(df_mat_trust.shape[1],activation=\"relu\",name='social_output')(social_decoded)\n",
        "\n",
        "  autoencoder = tf.keras.Model(inputs = [rating_input,social_input], outputs = [rating_output,social_output])\n",
        "\n",
        "  return autoencoder\n",
        "\n",
        "def createAutoCF(modelID,input_fileID,target_fileID,nbrEpochs,lossF,OF,mid_layer_ratio,nb_layers):\n",
        "\n",
        "  sparseDf = loadDataset(input_fileID)\n",
        "  df_mat_filled = loadDataset(target_fileID)\n",
        "  df_mat = DatasetToUserItemDataFrame(sparseDf,'userID','itemID','rating')\n",
        "  x_train,x_test,y_train,y_test = train_test_split(df_mat,df_mat_filled)\n",
        "  model_trained = trainModel(modelID,nbrEpochs,lossF,OF,x_train,y_train,mid_layer_ratio,nb_layers)\n",
        "\n",
        "  return model_trained , x_test, y_test\n",
        "\n",
        "def createSS_HAE(modelID,input_rating_fileID,target_rating_fileID,trust_fileID,nbrEpochs,lossF,OF,mid_layer_ratio,nb_layers):\n",
        "\n",
        "  sparseDf = loadDataset(input_rating_fileID)\n",
        "  df_rating_filled = loadDataset(target_rating_fileID)\n",
        "  df_trust_mat = loadDataset(trust_fileID)\n",
        "  trust_users_list = list(df_trust_mat.index)\n",
        "  df_rating_filled = getUsersRatings(df_rating_filled,trust_users_list) \n",
        "  df_rating_filled = orgDataframe(df_rating_filled,trust_users_list)\n",
        "\n",
        "  #input & target for autoencoder training\n",
        "  df_rating_mat = DatasetToUserItemDataFrame(sparseDf,'userID','itemID','rating')\n",
        "  df_rating_mat_filled = orgMatDataframe(df_rating_mat_filled,trust_users_list)\n",
        "\n",
        "  #data split\n",
        "  x_rating_train,x_rating_test,y_rating_train,y_rating_test = train_test_split(df_rating_mat,df_rating_mat_filled)\n",
        "  x_train,x_test = train_test_split(df_trust_mat)\n",
        "\n",
        "  model_trained = trainModel(modelID,nbrEpochs,lossF,OF,[x_rating_train,x_train],[y_rating_train,x_train],mid_layer_ratio,nb_layers)\n",
        "\n",
        "  return model_trained , [x_rating_test,y_rating_test] , x_test\n",
        "\n",
        "def evaluateModel(model,x_test,y_test):\n",
        "  model.evaluate(x_test,y_test) \n",
        "\n",
        "def orgDataframe(df_to_org,org_list):\n",
        "\n",
        "  df_org = pd.DataFrame(columns = ['userID','itemID','rating','reviewText'])\n",
        "  for user in org_list:\n",
        "    df_temp = df_to_org[(df_to_org['userID'] == user )]\n",
        "    df_org = pd.concat([df_org,df_temp])\n",
        "\n",
        "  return df_org\n",
        "\n",
        "def orgMatDataframe(df_to_org,org_list):\n",
        "  \n",
        "  df_org = pd.DataFrame(index = list(df_to_org.index),columns = list(df_to_org.columns))\n",
        "  for user in org_list:\n",
        "    df_org.loc[user] = list(df_to_org.loc[user])\n",
        "  \n",
        "  return df_org\n",
        "\n",
        "def getItemsScore(userID,modelID,fileID):\n",
        "  \n",
        "  listeItemScore = pd.DataFrame()\n",
        "  \n",
        "  if modelID == 0:\n",
        "    listItemScore = predSeCF(userID,modelID,fileID)   #CF\n",
        "  elif modelID == 1:\n",
        "    listItemScore = predSeCF(userID,modelID,fileID)   #CF + Sentiment\n",
        "  elif modelID == 2:\n",
        "    listItemScore = predSSeCF(userID,modelID,fileID)  #CF + Social\n",
        "  elif modelID == 3:\n",
        "    listItemScore = predSSeCF(userID,modelID,fileID)  #CF + Sentiment + Social\n",
        "\n",
        "  return listeItemScore \n",
        "\n",
        "def getModel(modelID):\n",
        "  model = tf.keras.models.load_model(MODEL_PATH[modelID])\n",
        "  return model\n",
        "\n",
        "def loadDataFrame(df):\n",
        "  df_loaded = pd.read_csv(DATA[df])\n",
        "  return  df_loaded\n",
        "\n",
        "def predSeCF(userID,modelID,fileID):\n",
        "  \n",
        "  model = getModel(modelID)\n",
        "  df_user_item_mat = pd.read_csv(DATA[fileID])\n",
        "  SparseScoresVec = df_user_item_mat.loc[userID].to_numpy()\n",
        "  listItemScores = df_user_item_mat.loc[userID].to_frame()\n",
        "  listItemScores = listItemScores.reset_index()\n",
        "  listItemScores.set_axis(['itemID','score'],axis='columns',inplace=True)\n",
        "  PredScoresVec = model.predict(SparseScoresVec)\n",
        "  listItemScores.replace(SparseScoresVec,PredScoresVec,inplace = True)\n",
        "\n",
        "  return listItemScores\n",
        "\n",
        "def predSSeCF(userID,modelID,ratings_fileID,trust_fileID):\n",
        "\n",
        "  model = getModel(modelID)\n",
        "  df_user_item_mat = loadDataset(fileID)\n",
        "  df_user_user_mat = pd.read_csv(trust_fileID)\n",
        "  SparseScoresVec = df_user_item_mat.loc[userID].to_numpy()\n",
        "  SparseTrustVec = df_user_user_mat.loc[userID].to_numpy()\n",
        "  listItemScores = df_user_item_mat.loc[userID].to_frame()\n",
        "  listItemScores = listItemScores.reset_index()\n",
        "  listItemScores.set_axis(['itemID','score'],axis='columns',inplace=True)\n",
        "  PredScoresVec,SparseTrustVec = model.predict([SparseScoresVec,SparseTrustVec])\n",
        "  listItemScores.replace(SparseScoresVec,PredScoresVec,inplace = True)\n",
        "\n",
        "  return listItemScores\n",
        "  "
      ],
      "metadata": {
        "id": "z6KHUFF9gwT5"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def datapreprocess(df_sample):\n",
        "\n",
        "  df_sample = df_sample.dropna(how='any',axis=0)\n",
        "  df_sample.rename(columns = {'reviewerID':'userID', 'productID' : 'itemID'},inplace = True)\n",
        "  df_sample.drop_duplicates(subset =['itemID', 'userID'] , keep = 'first' , inplace = True)\n",
        "  df_sample = generateIDs(df_sample,'userID','itemID',1000,2000+df_sample['userID'].nunique(),60000,61000+df_sample['itemID'].nunique())\n",
        "  print(\"== PREPROCESSING DATA ...\")\n",
        "  \n",
        "\n",
        "  df_sample['one'] = df_sample['rating'].apply(lambda x: 1 if x==1 else 0)\n",
        "  df_sample['two'] = df_sample['rating'].apply(lambda x: 1 if x==2 else 0)\n",
        "  df_sample['three'] = df_sample['rating'].apply(lambda x: 1 if x==3 else 0)\n",
        "  df_sample['four'] = df_sample['rating'].apply(lambda x: 1 if x==4 else 0)\n",
        "  df_sample['five'] = df_sample['rating'].apply(lambda x: 1 if x==5 else 0)\n",
        "  #df['six'] = df['rating'].apply(lambda x: 1 if x==6 else 0)\n",
        "  print(\"== DATA PREPROCESSED ==\")\n",
        "\n",
        "  return df_sample"
      ],
      "metadata": {
        "id": "EHC86cO8GJcK"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sample.shape"
      ],
      "metadata": {
        "id": "zA_oE3XPXfBi",
        "outputId": "830f4480-9136-454a-f1fb-cf057817e734",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(49748, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_sample = df_sample.dropna(how='any',axis=0)\n",
        "df_sample.rename(columns = {'reviewerID':'userID', 'productID' : 'itemID'},inplace = True)\n",
        "df_sample.drop_duplicates(subset =['itemID', 'userID'] , keep = 'first' , inplace = True)"
      ],
      "metadata": {
        "id": "WPaVB0D7XaT2"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = datapreprocess(df_sample)"
      ],
      "metadata": {
        "id": "c3PUFoU5GrhR",
        "outputId": "e66c38ca-f731-4d99-ecbd-0a31030c998b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100% (34064 of 34064) |##################| Elapsed Time: 0:05:08 Time:  0:05:08\n",
            "100% (3138 of 3138) |####################| Elapsed Time: 0:00:27 Time:  0:00:27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== PREPROCESSING DATA ...\n",
            "== DATA PREPROCESSED ==\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_mat_filled = genGMFmat(df_sample,df_test,'GMF',0,5,tf.keras.losses.CategoricalCrossentropy(),'adam',32)"
      ],
      "metadata": {
        "id": "tMniLDY_-vSc",
        "outputId": "5057b3d1-6aca-4849-b9d0-cd7731370fc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1070/1070 [==============================] - 8s 7ms/step - loss: 1.4239 - accuracy: 0.5202 - mae: 0.2960 - root_mean_squared_error: 0.3776 - precision: 0.4769 - val_loss: 1.3507 - val_accuracy: 0.5084 - val_mae: 0.2787 - val_root_mean_squared_error: 0.3679 - val_precision: 0.0000e+00\n",
            "Epoch 2/5\n",
            "1070/1070 [==============================] - 7s 6ms/step - loss: 1.2726 - accuracy: 0.5211 - mae: 0.2635 - root_mean_squared_error: 0.3568 - precision: 0.8557 - val_loss: 1.3428 - val_accuracy: 0.5083 - val_mae: 0.2699 - val_root_mean_squared_error: 0.3671 - val_precision: 0.5063\n",
            "Epoch 3/5\n",
            "1070/1070 [==============================] - 7s 6ms/step - loss: 0.7847 - accuracy: 0.7007 - mae: 0.1865 - root_mean_squared_error: 0.2744 - precision: 0.9927 - val_loss: 1.4053 - val_accuracy: 0.4815 - val_mae: 0.2801 - val_root_mean_squared_error: 0.3750 - val_precision: 0.4881\n",
            "Epoch 4/5\n",
            "1070/1070 [==============================] - 7s 6ms/step - loss: 0.2643 - accuracy: 0.9782 - mae: 0.0779 - root_mean_squared_error: 0.1451 - precision: 0.9995 - val_loss: 1.5196 - val_accuracy: 0.4399 - val_mae: 0.2877 - val_root_mean_squared_error: 0.3860 - val_precision: 0.4332\n",
            "Epoch 5/5\n",
            "1070/1070 [==============================] - 7s 6ms/step - loss: 0.0774 - accuracy: 0.9995 - mae: 0.0265 - root_mean_squared_error: 0.0646 - precision: 0.9999 - val_loss: 1.6118 - val_accuracy: 0.4160 - val_mae: 0.2901 - val_root_mean_squared_error: 0.3931 - val_precision: 0.3969\n",
            "311/311 [==============================] - 1s 4ms/step - loss: 1.5878 - accuracy: 0.4176 - mae: 0.2895 - root_mean_squared_error: 0.3914 - precision: 0.4010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            " 10% (3545 of 34064) |#                  | Elapsed Time: 0:04:07 ETA:   1:11:10"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_mat_filled.head()"
      ],
      "metadata": {
        "id": "3b7mpg60dEsv",
        "outputId": "f5e74457-9428-42fc-f449-3ed612eeebf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                7508492919  7532385086  7887421268  8288853439  8288862993  \\\n",
              "A24E3SXTC62LJI           5           5           5           5           5   \n",
              "A269FLZCB4GIPV           5           5           5           5           5   \n",
              "AB6CHQWHZW4TV            3           5           5           5           5   \n",
              "A1M117A53LEI8            2           5           5           5           5   \n",
              "A272DUT8M88ZS8           5           5           5           5           5   \n",
              "\n",
              "                8288878881  828886922X  8199900164  9578085451  961301375X  \\\n",
              "A24E3SXTC62LJI           5           5           5           5           5   \n",
              "A269FLZCB4GIPV           5           5           5           5           5   \n",
              "AB6CHQWHZW4TV            5           5           5           5           5   \n",
              "A1M117A53LEI8            5           5           5           5           5   \n",
              "A272DUT8M88ZS8           5           5           5           5           5   \n",
              "\n",
              "                ...  B001EN2ZNC  B001EO9XAE  B001EPPLYU  B001ET5X9Y  \\\n",
              "A24E3SXTC62LJI  ...           5           5           5           5   \n",
              "A269FLZCB4GIPV  ...           5           5           5           5   \n",
              "AB6CHQWHZW4TV   ...           5           5           5           5   \n",
              "A1M117A53LEI8   ...           5           5           5           5   \n",
              "A272DUT8M88ZS8  ...           5           5           5           5   \n",
              "\n",
              "                B001ETRNAQ  B001EULXGU  B001EX6LJ6  B001EXXFEK  B001EZMGE8  \\\n",
              "A24E3SXTC62LJI           5           5           5           5           5   \n",
              "A269FLZCB4GIPV           5           5           5           5           5   \n",
              "AB6CHQWHZW4TV            5           5           5           5           5   \n",
              "A1M117A53LEI8            5           5           5           4           5   \n",
              "A272DUT8M88ZS8           5           5           5           5           5   \n",
              "\n",
              "                B001EZQAZ4  \n",
              "A24E3SXTC62LJI           5  \n",
              "A269FLZCB4GIPV           5  \n",
              "AB6CHQWHZW4TV            5  \n",
              "A1M117A53LEI8            5  \n",
              "A272DUT8M88ZS8           5  \n",
              "\n",
              "[5 rows x 765 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6e1c8a1a-32be-47e5-b969-09141f651a0a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>7508492919</th>\n",
              "      <th>7532385086</th>\n",
              "      <th>7887421268</th>\n",
              "      <th>8288853439</th>\n",
              "      <th>8288862993</th>\n",
              "      <th>8288878881</th>\n",
              "      <th>828886922X</th>\n",
              "      <th>8199900164</th>\n",
              "      <th>9578085451</th>\n",
              "      <th>961301375X</th>\n",
              "      <th>...</th>\n",
              "      <th>B001EN2ZNC</th>\n",
              "      <th>B001EO9XAE</th>\n",
              "      <th>B001EPPLYU</th>\n",
              "      <th>B001ET5X9Y</th>\n",
              "      <th>B001ETRNAQ</th>\n",
              "      <th>B001EULXGU</th>\n",
              "      <th>B001EX6LJ6</th>\n",
              "      <th>B001EXXFEK</th>\n",
              "      <th>B001EZMGE8</th>\n",
              "      <th>B001EZQAZ4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>A24E3SXTC62LJI</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A269FLZCB4GIPV</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AB6CHQWHZW4TV</th>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A1M117A53LEI8</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A272DUT8M88ZS8</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 765 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e1c8a1a-32be-47e5-b969-09141f651a0a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6e1c8a1a-32be-47e5-b969-09141f651a0a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6e1c8a1a-32be-47e5-b969-09141f651a0a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    }
  ]
}